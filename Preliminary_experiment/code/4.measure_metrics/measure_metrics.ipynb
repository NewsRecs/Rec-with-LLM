{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## measure_metrics 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "\n",
    "def read_hidden_positions(file_path):\n",
    "    \"\"\"\n",
    "    question 정답 위치 정보를 읽어오는 함수\n",
    "    \"\"\"\n",
    "    hidden_positions = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            match = re.match(r'U(\\d+)\\s*:\\s*\\[(.*?)\\]', line.strip())\n",
    "            if match:\n",
    "                user_id = int(match.group(1))   # 사용자 ID 추출\n",
    "                positions = list(map(int, match.group(2).split(','))) # 정답 위치 리스트 추출\n",
    "                hidden_positions[user_id] = positions\n",
    "    return hidden_positions\n",
    "\n",
    "def read_predicted_rankings(file_path):\n",
    "    \"\"\"\n",
    "    예측된 순위를 읽어오는 함수\n",
    "    \"\"\"\n",
    "    predicted_rankings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        users = re.findall(r'\\[U(\\d+)\\](.*?)(?=\\n\\[U\\d+\\]|\\Z)', content, re.DOTALL) # user별 예측 데이터 추출\n",
    "        for user in users:\n",
    "            user_id = int(user[0])  # user ID 추출\n",
    "            user_content = user[1]\n",
    "            questions = re.findall(r'Question\\s*(\\d+)\\s*[:：]\\s*(.*?)(?=\\nQuestion\\s*\\d+\\s*[:：]|\\n\\[U\\d+\\]|\\Z)', user_content, re.DOTALL)\n",
    "            rankings = {}\n",
    "            for q in questions:\n",
    "                q_num = int(q[0])   # 질문 번호 추출\n",
    "                ranking_str = q[1].strip().replace(' ', '')         # 순위 문자열 추출 후 공백 제거\n",
    "                ranking = list(map(int, ranking_str.split(',')))    # 순위를 리스트로 변환\n",
    "                rankings[q_num] = ranking\n",
    "            predicted_rankings[user_id] = rankings\n",
    "    return predicted_rankings\n",
    "\n",
    "def compute_ndcg_at_5(rankings, hidden_positions):\n",
    "    \"\"\"\n",
    "    nDCG@5 및 정확도를 계산하는 함수\n",
    "    \"\"\"\n",
    "    user_ndcg = {}\n",
    "    question_ndcg = []\n",
    "\n",
    "    # 정확도 계산을 위한 변수 초기화\n",
    "    total_questions = 0\n",
    "    total_correct_top1 = 0\n",
    "    user_accuracy = {}\n",
    "    user_correct_counts = {}\n",
    "    user_total_questions = {}\n",
    "\n",
    "    for user_id, user_rankings in rankings.items():\n",
    "        if user_id not in hidden_positions:   # user id가 없으면 무시\n",
    "            continue\n",
    "        user_positions = hidden_positions[user_id]\n",
    "        ndcg_values = []\n",
    "        correct_top1_count = 0\n",
    "        total_user_questions = 0\n",
    "        for q_num, ranking in user_rankings.items():\n",
    "            if q_num - 1 >= len(user_positions):    # 정답 리스트에 없는 질문 번호는 무시\n",
    "                continue\n",
    "            correct_position = user_positions[q_num - 1]    # 올바른 위치\n",
    "            correct_item = correct_position  # question의 news는 1부터 5까지 번호가 매겨져 있음\n",
    "            total_questions += 1\n",
    "            total_user_questions += 1\n",
    "\n",
    "            # nDCG 계산\n",
    "            if correct_item in ranking: # 정답 뉴스가 순위 리스트에 있을 경우\n",
    "                rank = ranking.index(correct_item) + 1  # 해당 뉴스의 순위 (1부터 시작)\n",
    "                if rank <= 5:\n",
    "                    ndcg = 1 / math.log2(rank + 1)  # nDCG 계산\n",
    "                else:\n",
    "                    ndcg = 0\n",
    "            else:   # 정답 뉴스가 없을 경우 NDCG는 0\n",
    "                ndcg = 0\n",
    "            ndcg_values.append((q_num, ndcg))\n",
    "            question_ndcg.append(ndcg)\n",
    "\n",
    "            # 정확도 계산\n",
    "            if correct_item == ranking[0]:\n",
    "                correct_top1_count += 1\n",
    "                total_correct_top1 += 1\n",
    "\n",
    "        avg_ndcg = sum(ndcg for _, ndcg in ndcg_values) / len(ndcg_values) if ndcg_values else 0    # user의 평균 nDCG 계산\n",
    "        accuracy = correct_top1_count / total_user_questions if total_user_questions else 0\n",
    "        user_accuracy[user_id] = accuracy\n",
    "        user_correct_counts[user_id] = correct_top1_count\n",
    "        user_total_questions[user_id] = total_user_questions\n",
    "        user_ndcg[user_id] = (avg_ndcg, ndcg_values)\n",
    "\n",
    "    # 전체 USER 정확도 계산 (사용자별 정확도의 평균)\n",
    "    overall_user_accuracy = sum(user_accuracy.values()) / len(user_accuracy) if user_accuracy else 0\n",
    "    # 전체 Question 정확도 계산\n",
    "    overall_question_accuracy = total_correct_top1 / total_questions if total_questions else 0\n",
    "\n",
    "    return user_ndcg, question_ndcg, user_accuracy, overall_user_accuracy, overall_question_accuracy, total_correct_top1, total_questions, user_correct_counts, user_total_questions\n",
    "\n",
    "def write_results(file_path, user_ndcg, overall_user_ndcg, overall_question_ndcg, user_accuracy, overall_user_accuracy, overall_question_accuracy, total_correct_top1, total_questions, user_correct_counts, user_total_questions):\n",
    "    \"\"\"\n",
    "    metrics 결과 작성 함수\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f'전체 USER 평균 nDCG@5 : {overall_user_ndcg:.3f}\\n')\n",
    "        f.write(f'전체 Question nDCG@5 : {overall_question_ndcg:.3f}\\n\\n')\n",
    "        f.write(f'전체 USER 평균 Accuracy : {overall_user_accuracy:.3f}\\n')\n",
    "        f.write(f'전체 Question Accuracy : {overall_question_accuracy:.3f} ({total_correct_top1} / {total_questions})\\n')\n",
    "        f.write('\\n-----------------------------------------------------------\\n\\n')\n",
    "        for user_id in sorted(user_ndcg.keys()):\n",
    "            avg_ndcg, ndcg_values = user_ndcg[user_id]\n",
    "            accuracy = user_accuracy.get(user_id, 0)\n",
    "            correct_top1_count = user_correct_counts.get(user_id, 0)\n",
    "            total_user_questions = user_total_questions.get(user_id, 0)\n",
    "            f.write(f'[U{user_id}] : 평균 nDCG@5 : {avg_ndcg:.3f}  |  Accuracy : {accuracy:.3f} ({correct_top1_count}/{total_user_questions})\\n')\n",
    "            for q_num, ndcg in sorted(ndcg_values):\n",
    "                f.write(f'Question {q_num} : nDCG@5 = {ndcg:.3f}\\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "def measure_metrics(target_file, target_folder, purpose):\n",
    "    \"\"\"\n",
    "    metric 측정 main 함수\n",
    "    \"\"\"\n",
    "\n",
    "    target_folder = f'../../prompts/{target_folder}'\n",
    "\n",
    "    if purpose == 'new_negative':\n",
    "        hidden_file = f'{target_folder}/metadata/hidden_positions.txt'\n",
    "    else:\n",
    "        hidden_file = f'{target_folder}/{purpose}/metadata/hidden_positions.txt'\n",
    "    \n",
    "    output_file = f'{target_file.replace(\".txt\",\"\")}_metrics.txt'\n",
    "    \n",
    "    predicted_rankings = read_predicted_rankings(os.path.join('../../results/gpt_result', target_file))    # 예측된 순위 읽기\n",
    "    hidden_positions = read_hidden_positions(hidden_file)   # 숨겨진 위치 읽기\n",
    "    user_ndcg, question_ndcg_values, user_accuracy, overall_user_accuracy, overall_question_accuracy, total_correct_top1, total_questions, user_correct_counts, user_total_questions = compute_ndcg_at_5(predicted_rankings, hidden_positions)   # NDCG@5 및 정확도 계산\n",
    "    overall_user_ndcg = sum(avg for avg, _ in user_ndcg.values()) / len(user_ndcg) if user_ndcg else 0  # 전체 사용자 평균 NDCG 계산\n",
    "    overall_question_ndcg = sum(question_ndcg_values) / len(question_ndcg_values) if question_ndcg_values else 0    # 전체 질문 평균 NDCG 계산\n",
    "    os.makedirs(os.path.join('../../results', 'metrics'), exist_ok=True) # 출력 디렉터리 생성\n",
    "    write_results(\n",
    "        os.path.join('../../results', 'metrics', output_file),\n",
    "        user_ndcg,\n",
    "        overall_user_ndcg,\n",
    "        overall_question_ndcg,\n",
    "        user_accuracy,\n",
    "        overall_user_accuracy,\n",
    "        overall_question_accuracy,\n",
    "        total_correct_top1,\n",
    "        total_questions,\n",
    "        user_correct_counts,\n",
    "        user_total_questions\n",
    "    )    # 결과를 파일에 쓰기\n",
    "    print(f'{output_file} 생성 완료 (대상 : {target_file})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241230-5] negative_3_metrics.txt 생성 완료 (대상 : [241230-5] negative_3.txt)\n"
     ]
    }
   ],
   "source": [
    "# measure_metrics(target_file='[241223-3] positive.txt', target_folder = \"[241223-3] 1~1000\", purpose='only_positive')\n",
    "measure_metrics(target_file='[241230-5] negative_3.txt', target_folder = \"[241230-5] 1~1000\", purpose='with_negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coongya11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
