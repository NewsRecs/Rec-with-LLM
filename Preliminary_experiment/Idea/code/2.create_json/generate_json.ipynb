{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 & Instuction 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "# negative용\n",
    "instruction_negative = \"\"\"\n",
    "You are a bot that identifies users' news interests from [News of Interest to the user] and, based on this, predicts which news among the candidate news in [Question] the user is most likely to read.\n",
    "\n",
    "News is provided by title only. \n",
    "News is Norwegian news in Norwegian.\n",
    "\n",
    "There can be multiple lists in [News of interest to the user], each with five news items.\n",
    "Of the five news in each list, there is one news that users are most interested in.\n",
    "\n",
    "[Questions] can have multiple questions, each of which must be answered.\n",
    "The answer should return only one news article that the user is most likely to read.\n",
    "\n",
    "<example>\n",
    "[News of interest to the user]\n",
    "1. På dette bildet skiller Magnus Carlsen seg ut: - Litt tilfeldig / Kong Harald: - Litt uvirkelig å bli 80 / Se lesernes nyttårsbilder / Måtte i oppvaskmøte etter å ha kritisert landslaget / Her koker det over for Tønseth. Så stakk han fra stadion i sinne.\n",
    "Of the five news above, the news that the user is most interested in : Se lesernes nyttårsbilder\n",
    "2. Døddrukne ungdommer, trusler, vold og skadeverk / Istanbul: Politiet jakter gjerningsmann som drepte 39 mennesker nyttårsaften / Bil ble totalvrak etter krasj med bergvegg / Bolig totalskadd i brann / Åpenbart beruset mann i trafikkulykke på Byåsen\n",
    "Of the five news above, the news that the user is most interested in : Åpenbart beruset mann i trafikkulykke på Byåsen\n",
    "...\n",
    "\n",
    "[Questions]\n",
    "Returns the most likely clickable news among the candidate news for each question based on the user's news interests.\n",
    "Question 1) 1: Fotballsupporternes opptrinn i Paris ble fordømt av statsministeren. Nå har de fått straffen sin. / 2: Disse vil bli lensmann i Meråker og Frosta / 3: Mann kritisk skadd i MC-ulykke i Akershus / 4: Vurderer å flytte fra Midtbyen / 5: Saktegående trafikk i Moholtlia\n",
    "Question 2) 1: Får bygge på hytte nær vernet vassdrag / 2: Nidarosdomen har hovedrollen i norsk variant av «Da Vinci-koden» / 3: Høyre vil etablere norsk «kulturkanon» / 4: Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut / 5: Ungdom får tilbake førerkort for å bli yrkessjåfør\n",
    "...\n",
    "Don't explain why in your answer, just return the number of the news.\n",
    "\n",
    "<answer>\n",
    "Question 1 : 3\n",
    "Question 2 : 5\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# positive용\n",
    "instruction_positive = \"\"\"\n",
    "You are a bot that identifies users' news interests from [click history] and, based on this, predicts which news among the candidate news in [Question] the user is most likely to read.\n",
    "\n",
    "News is provided by title only.\n",
    "News is Norwegian news in Norwegian.\n",
    "\n",
    "[Questions] can have multiple questions, each of which must be answered.\n",
    "The answer should return only one news article that the user is most likely to read.\n",
    "\n",
    "<example>\n",
    "[Click History]\n",
    "1. click : Se lesernes nyttårsbilder\n",
    "2. click : Åpenbart beruset mann i trafikkulykke på Byåsen\n",
    "...\n",
    "\n",
    "[Questions]\n",
    "Returns the most likely clickable news among the candidate news for each question based on the user's news interests.\n",
    "Question 1) 1: Fotballsupporternes opptrinn i Paris ble fordømt av statsministeren. Nå har de fått straffen sin. / 2: Disse vil bli lensmann i Meråker og Frosta / 3: Mann kritisk skadd i MC-ulykke i Akershus / 4: Vurderer å flytte fra Midtbyen / 5: Saktegående trafikk i Moholtlia\n",
    "Question 2) 1: Får bygge på hytte nær vernet vassdrag / 2: Nidarosdomen har hovedrollen i norsk variant av «Da Vinci-koden» / 3: Høyre vil etablere norsk «kulturkanon» / 4: Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut / 5: Ungdom får tilbake førerkort for å bli yrkessjåfør\n",
    "...\n",
    "Don't explain why in your answer, just return the number of the news.\n",
    "\n",
    "<answer>\n",
    "Question 1 : 3\n",
    "Question 2 : 5\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "instruction_demo_negative = \"\"\"\n",
    "You are a recommendation bot responsible for selecting the news article that the target user is most likely to prefer from a list of five candidate articles. The only information available for each candidate article is its title, which is written in Norwegian.\n",
    "Your goal is to predict the index number of the news article that best fits in the position labeled [MASK].\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(purpose, u_numbers, file_name, target_folder, demo = False):\n",
    "    \"\"\"\n",
    "    JSONL 파일 생성 함수\n",
    "    \"\"\"\n",
    "\n",
    "    target_folder = f'prompts/{target_folder}'\n",
    "    \n",
    "    # U*.txt 파일과 메타데이터가 포함된 디렉토리 경로\n",
    "    data_dir = f'{target_folder}/{purpose}'\n",
    "    metadata_dir = os.path.join(data_dir, 'metadata')\n",
    "    positions_file = os.path.join(metadata_dir, 'hidden_positions.txt')\n",
    "\n",
    "    if purpose == \"only_positive\":\n",
    "        instruction = instruction_positive\n",
    "    elif purpose == \"with_negative\":\n",
    "        if demo:\n",
    "            instruction = instruction_demo_negative\n",
    "        else:\n",
    "            instruction = instruction_negative\n",
    "\n",
    "    # 1단계: hidden_positions.txt 읽기\n",
    "    hidden_positions = {}\n",
    "    with open(positions_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # 'U1   : [1, 3, 3, 4]'와 같은 형식의 라인 매칭\n",
    "            match = re.match(r'(U\\d+)\\s*:\\s*\\[([^\\]]+)\\]', line)\n",
    "            if match:\n",
    "                user_id = match.group(1)\n",
    "                positions_str = match.group(2)\n",
    "                # 위치를 정수의 리스트로 변환\n",
    "                positions = [int(pos.strip()) for pos in positions_str.split(',')]\n",
    "                hidden_positions[user_id] = positions\n",
    "\n",
    "    # 2단계: 지정된 U 번호의 각 U*.txt 파일 처리\n",
    "    data = []\n",
    "    for u_num in u_numbers:\n",
    "        user_id = f'U{u_num}'\n",
    "        user_file = f'{user_id}.txt'\n",
    "        user_file_path = os.path.join(data_dir, user_file)\n",
    "        if not os.path.exists(user_file_path):\n",
    "            continue  # 파일이 없으면 스킵\n",
    "        # 사용자 파일의 내용 읽기\n",
    "        with open(user_file_path, 'r', encoding='utf-8') as f:\n",
    "            prompt = f.read()\n",
    "\n",
    "        # 콘텐츠에서 질문 추출\n",
    "        # '[Questions]' 섹션 아래의 질문을 가정\n",
    "        questions_section = re.search(r'\\[Questions\\](.*)', prompt, re.DOTALL)\n",
    "        if not questions_section:\n",
    "            continue  # 질문이 없으면 스킵\n",
    "        questions_text = questions_section.group(1)\n",
    "        # 개별 질문으로 분할\n",
    "        questions = {}\n",
    "        for match in re.finditer(r'Question\\s*(\\d+)\\)(.*?)(?=Question\\s*\\d+\\)|$)', questions_text, re.DOTALL):\n",
    "            q_num = int(match.group(1))\n",
    "            q_content = match.group(2).strip()\n",
    "            questions[q_num] = q_content\n",
    "\n",
    "        # 해당 사용자의 정답 위치 가져오기\n",
    "        positions = hidden_positions.get(user_id, [])\n",
    "        assistant_content_lines = []\n",
    "        for idx, (q_num, q_content) in enumerate(sorted(questions.items())):\n",
    "            # 정답 위치 가져오기\n",
    "            if idx < len(positions):\n",
    "                correct_position = positions[idx]\n",
    "            else:\n",
    "                # 질문 수보다 위치가 적으면 랜덤으로 정답 위치 할당\n",
    "                correct_position = random.randint(1, 5)\n",
    "            # 어시스턴트의 콘텐츠 형식화 (정답 값만 포함)\n",
    "            assistant_content_lines.append(f\"Question {q_num}: {correct_position}\")\n",
    "\n",
    "        assistant_content = '\\n'.join(assistant_content_lines)\n",
    "\n",
    "        # 데이터 항목 구성\n",
    "        data_entry = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "            ]\n",
    "        }\n",
    "        data.append(data_entry)\n",
    "\n",
    "    # 이제 'data'에는 지정된 U 번호의 사용자의 처리된 데이터가 포함되어 있음\n",
    "    # JSONL 형식으로 저장\n",
    "    output_file = f'gpt_finetuning_data/{file_name}'\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for data_entry in data:\n",
    "            json_line = json.dumps(data_entry, ensure_ascii=False)\n",
    "            f.write(json_line + '\\n')\n",
    "\n",
    "    print(f\"처리된 데이터가 {output_file}으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 데이터가 gpt_finetuning_data/train_positive_55_ver2.jsonl으로 저장되었습니다.\n",
      "처리된 데이터가 gpt_finetuning_data/val_positive_55_ver2.jsonl으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 처리할 User 번호를 임의로 지정 (예: U3, U7, U9)\n",
    "train_numbers = [i for i in range(15001,15056)]\n",
    "val_numbers = [i for i in range(15056,15071)]\n",
    "# train_numbers = [1327, 1280, 1448, 1005, 1019, 1044, 1425, 1496, 1295, 1194, 1208, 1074, 1273, 1351, 1083, 1478, 1070, 1267, 1150, 1061]\n",
    "# val_numbers = [1105, 1328, 1147, 1374, 1477, 1038, 1433, 1096, 1334, 1275]\n",
    "\n",
    "create_json('only_positive', train_numbers, \"train_positive_55_ver2.jsonl\")\n",
    "create_json('only_positive', val_numbers, \"val_positive_55_ver2.jsonl\")\n",
    "\n",
    "create_json('with_negative', train_numbers, \"train_negative_55_ver2.jsonl\")\n",
    "create_json('with_negative', val_numbers, \"val_negative_55_ver2.jsonl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U15001.txt\n",
      "U15002.txt\n",
      "U15003.txt\n",
      "U15004.txt\n",
      "U15005.txt\n",
      "U15006.txt\n",
      "U15007.txt\n",
      "U15008.txt\n",
      "U15009.txt\n",
      "U15010.txt\n",
      "U15011.txt\n",
      "U15012.txt\n",
      "U15013.txt\n",
      "U15014.txt\n",
      "U15015.txt\n",
      "U15016.txt\n",
      "U15017.txt\n",
      "U15018.txt\n",
      "U15019.txt\n",
      "U15020.txt\n",
      "U15021.txt\n",
      "U15022.txt\n",
      "U15023.txt\n",
      "U15024.txt\n",
      "U15025.txt\n",
      "U15026.txt\n",
      "U15027.txt\n",
      "U15028.txt\n",
      "U15029.txt\n",
      "U15030.txt\n",
      "U15031.txt\n",
      "U15032.txt\n",
      "U15033.txt\n",
      "U15034.txt\n",
      "U15035.txt\n",
      "U15036.txt\n",
      "U15037.txt\n",
      "U15038.txt\n",
      "U15039.txt\n",
      "U15040.txt\n",
      "U15041.txt\n",
      "U15042.txt\n",
      "U15043.txt\n",
      "U15044.txt\n",
      "U15045.txt\n",
      "U15046.txt\n",
      "U15047.txt\n",
      "U15048.txt\n",
      "U15049.txt\n",
      "U15050.txt\n",
      "U15051.txt\n",
      "U15052.txt\n",
      "U15053.txt\n",
      "U15054.txt\n",
      "U15055.txt\n",
      "처리된 데이터가 gpt_finetuning_data/train_negative_demo.jsonl으로 저장되었습니다.\n",
      "U15056.txt\n",
      "U15057.txt\n",
      "U15058.txt\n",
      "U15059.txt\n",
      "U15060.txt\n",
      "U15061.txt\n",
      "U15062.txt\n",
      "U15063.txt\n",
      "U15064.txt\n",
      "U15065.txt\n",
      "U15066.txt\n",
      "U15067.txt\n",
      "U15068.txt\n",
      "U15069.txt\n",
      "U15070.txt\n",
      "처리된 데이터가 gpt_finetuning_data/val_negative_demo.jsonl으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "train_numbers = [i for i in range(15001,15056)]\n",
    "val_numbers = [i for i in range(15056,15071)]\n",
    "\n",
    "create_json(purpose='with_negative', \n",
    "            u_numbers=train_numbers, \n",
    "            file_name=\"train_negative_demo.jsonl\", \n",
    "            target_folder='user_prompts_demo_fine', \n",
    "            demo=True)\n",
    "\n",
    "create_json(purpose='with_negative', \n",
    "            u_numbers=val_numbers, \n",
    "            file_name=\"val_negative_demo.jsonl\", \n",
    "            target_folder=\"user_prompts_demo_fine\", \n",
    "            demo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 데이터가 gpt_finetuning_data/[241216] train_negative_demo.jsonl으로 저장되었습니다.\n",
      "처리된 데이터가 gpt_finetuning_data/[241216] val_negative_demo.jsonl으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "train_numbers = [i for i in range(15001,15056)]\n",
    "val_numbers = [i for i in range(15056,15071)]\n",
    "\n",
    "create_json(purpose='with_negative', \n",
    "            u_numbers=train_numbers, \n",
    "            file_name=\"[241216] train_negative_demo.jsonl\", \n",
    "            target_folder='[241216] user_prompts_demo_fine'\n",
    "            )\n",
    "\n",
    "create_json(purpose='with_negative', \n",
    "            u_numbers=val_numbers, \n",
    "            file_name=\"[241216] val_negative_demo.jsonl\", \n",
    "            target_folder=\"[241216] user_prompts_demo_fine\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssam_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
