{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_top_n_users_by_accuracy(filename, n, min_questions):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    user_pattern = re.findall(r'\\[(U\\d+)] : 평균 nDCG@5 : ([\\d.]+)  \\|  평균 nDCG@10 : ([\\d.]+)  \\|  Accuracy : ([\\d.]+) \\((\\d+)/(\\d+)\\)', data)\n",
    "    \n",
    "    users = []\n",
    "    for user in user_pattern:\n",
    "        user_id, ndcg5, ndcg10, accuracy, correct, total = user\n",
    "        total = int(total)\n",
    "        if total >= min_questions:\n",
    "            accuracy = float(accuracy)\n",
    "            users.append((user_id, float(ndcg5), float(ndcg10), accuracy, int(correct), total))\n",
    "    \n",
    "    top_users = sorted(users, key=lambda x: x[3], reverse=True)[:n]\n",
    "    \n",
    "    for i, (user_id, ndcg5, ndcg10, accuracy, correct, total) in enumerate(top_users, 1):\n",
    "        print(f\"{i}. {user_id} [ 평균 nDCG@5 : {ndcg5:.3f}  |  평균 nDCG@10 : {ndcg10:.3f}  |  Accuracy : {accuracy:.3f} ({correct}/{total}) ]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. U53 [ 평균 nDCG@5 : 0.400  |  평균 nDCG@10 : 0.400  |  Accuracy : 0.400 (6/15) ]\n",
      "2. U525 [ 평균 nDCG@5 : 0.400  |  평균 nDCG@10 : 0.400  |  Accuracy : 0.400 (4/10) ]\n",
      "3. U138 [ 평균 nDCG@5 : 0.364  |  평균 nDCG@10 : 0.364  |  Accuracy : 0.364 (4/11) ]\n",
      "4. U607 [ 평균 nDCG@5 : 0.364  |  평균 nDCG@10 : 0.364  |  Accuracy : 0.364 (4/11) ]\n",
      "5. U839 [ 평균 nDCG@5 : 0.364  |  평균 nDCG@10 : 0.364  |  Accuracy : 0.364 (4/11) ]\n",
      "6. U745 [ 평균 nDCG@5 : 0.353  |  평균 nDCG@10 : 0.353  |  Accuracy : 0.353 (6/17) ]\n",
      "7. U564 [ 평균 nDCG@5 : 0.350  |  평균 nDCG@10 : 0.350  |  Accuracy : 0.350 (7/20) ]\n",
      "8. U725 [ 평균 nDCG@5 : 0.350  |  평균 nDCG@10 : 0.350  |  Accuracy : 0.350 (7/20) ]\n",
      "9. U246 [ 평균 nDCG@5 : 0.333  |  평균 nDCG@10 : 0.333  |  Accuracy : 0.333 (5/15) ]\n",
      "10. U356 [ 평균 nDCG@5 : 0.333  |  평균 nDCG@10 : 0.333  |  Accuracy : 0.333 (4/12) ]\n"
     ]
    }
   ],
   "source": [
    "# 예제 실행\n",
    "file_name = '[250220] negative_acc2_metrics.txt'\n",
    "file_name = f'../../results/metrics/{file_name}'\n",
    "get_top_n_users_by_accuracy(file_name, n=10, min_questions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. U15197 [ 평균 nDCG@5 : 0.800  |  평균 nDCG@10 : 0.800  |  Accuracy : 0.800 (4/5) ]\n",
      "2. U15093 [ 평균 nDCG@5 : 0.714  |  평균 nDCG@10 : 0.714  |  Accuracy : 0.714 (5/7) ]\n",
      "3. U15473 [ 평균 nDCG@5 : 0.667  |  평균 nDCG@10 : 0.667  |  Accuracy : 0.667 (4/6) ]\n",
      "4. U15142 [ 평균 nDCG@5 : 0.600  |  평균 nDCG@10 : 0.600  |  Accuracy : 0.600 (3/5) ]\n",
      "5. U15098 [ 평균 nDCG@5 : 0.500  |  평균 nDCG@10 : 0.500  |  Accuracy : 0.500 (3/6) ]\n",
      "6. U15083 [ 평균 nDCG@5 : 0.455  |  평균 nDCG@10 : 0.455  |  Accuracy : 0.455 (5/11) ]\n",
      "7. U15426 [ 평균 nDCG@5 : 0.429  |  평균 nDCG@10 : 0.429  |  Accuracy : 0.429 (3/7) ]\n",
      "8. U15056 [ 평균 nDCG@5 : 0.400  |  평균 nDCG@10 : 0.400  |  Accuracy : 0.400 (2/5) ]\n",
      "9. U15185 [ 평균 nDCG@5 : 0.400  |  평균 nDCG@10 : 0.400  |  Accuracy : 0.400 (2/5) ]\n",
      "10. U15227 [ 평균 nDCG@5 : 0.400  |  평균 nDCG@10 : 0.400  |  Accuracy : 0.400 (2/5) ]\n"
     ]
    }
   ],
   "source": [
    "file_name = '[fine2] negative_metrics.txt'\n",
    "file_name = f'../../results/metrics/{file_name}'\n",
    "get_top_n_users_by_accuracy(file_name, n=10, min_questions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(file_path):\n",
    "    \"\"\"Parse the given txt file and return a dictionary of user accuracy and correct questions.\"\"\"\n",
    "    user_data = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    user_id = None\n",
    "    for line in content:\n",
    "        user_match = re.match(r'\\[(U\\d+)]', line)\n",
    "        if user_match:\n",
    "            user_id = user_match.group(1)\n",
    "            acc_match = re.search(r'Accuracy : ([0-9\\.]+) \\((\\d+)/(\\d+)\\)', line)\n",
    "            if acc_match:\n",
    "                accuracy = float(acc_match.group(1))\n",
    "                correct_answers = set()\n",
    "                user_data[user_id] = {'accuracy': accuracy, 'correct_answers': correct_answers}\n",
    "        \n",
    "        question_match = re.match(r'\\s*- Question (\\d+) : nDCG@5 = ([0-9\\.]+)', line)\n",
    "        if question_match and user_id:\n",
    "            question_num = int(question_match.group(1))\n",
    "            ndcg_5 = float(question_match.group(2))\n",
    "            if ndcg_5 == 1.0:\n",
    "                user_data[user_id]['correct_answers'].add(question_num)\n",
    "    \n",
    "    return user_data\n",
    "\n",
    "def compare_users(abc_path, qwe_path):\n",
    "    \"\"\"Compare users based on Accuracy from two files and count various categories.\"\"\"\n",
    "    abc_users = parse_txt(abc_path)\n",
    "    qwe_users = parse_txt(qwe_path)\n",
    "    \n",
    "    higher, equal, lower = 0, 0, 0\n",
    "    same_correct_questions = 0\n",
    "    \n",
    "    for user in qwe_users:\n",
    "        if user in abc_users:\n",
    "            if qwe_users[user]['accuracy'] > abc_users[user]['accuracy']:\n",
    "                higher += 1\n",
    "            elif qwe_users[user]['accuracy'] < abc_users[user]['accuracy']:\n",
    "                lower += 1\n",
    "            else:\n",
    "                equal += 1\n",
    "                if qwe_users[user]['correct_answers'] == abc_users[user]['correct_answers']:\n",
    "                    same_correct_questions += 1\n",
    "    \n",
    "    return {\n",
    "        'higher_accuracy': higher,\n",
    "        'equal_accuracy': equal,\n",
    "        'lower_accuracy': lower,\n",
    "        'same_correct_questions': same_correct_questions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'higher_accuracy': 319,\n",
       " 'equal_accuracy': 442,\n",
       " 'lower_accuracy': 239,\n",
       " 'same_correct_questions': 331}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "file1 = '[250220] negative_ndcg2_metrics.txt'\n",
    "file1 = f'../../results/metrics/{file1}'\n",
    "\n",
    "file2 = '[250220] negative_acc2_metrics.txt'\n",
    "file2 = f'../../results/metrics/{file2}'\n",
    "\n",
    "result = compare_users(file1, file2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coongya11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
