{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "# tsv 파일을 DataFrame으로 읽기\n",
    "user = pd.read_csv('user.tsv', sep='\\t', names=['User', 'History', 'Train', 'Test'])\n",
    "user_raw = pd.read_csv('user(raw).tsv', sep='\\t',  names=['User', 'History', 'Train', 'Test'])\n",
    "\n",
    "history_news = pd.read_csv('history/news.tsv', sep='\\t',  names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "\n",
    "train_news = pd.read_csv('train/news.tsv', sep='\\t', names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "train_behaviors = pd.read_csv('train/behaviors.tsv', sep='\\t', names=['User ID', 'Click time', 'Click history', 'click'])\n",
    "\n",
    "test_news = pd.read_csv('test/news.tsv', sep='\\t', names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "test_behaviors = pd.read_csv('test/behaviors.tsv', sep='\\t', names=['User ID', 'Click time', 'Click history', 'click'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish 순서에 맞게 오름차순으로 정렬\n",
    "history_news_sorted = history_news.sort_values(by='Publish', ascending=True).reset_index(drop=True)\n",
    "# publish 순서에 맞게 오름차순으로 정렬\n",
    "train_news_sorted = train_news.sort_values(by='Publish', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Click History]\n",
      "1. click : Se lesernes nyttårsbilder \n",
      "2. click : Brannutrykning til kjøkken på Singsaker \n",
      "3. click : Emil Iversen sender bilder til Ustjugov på nettet \n",
      "4. click : Hvem syns du er Årets trønder? \n",
      "5. click : - Fast ansatte er et konkurransefortrinn \n",
      "6. click : Slik gikk det da elbilene måtte betale p-avgift \n",
      "7. click : - Jeg fikk svingt unna i siste liten \n",
      "8. click : Trafikkulykke på E14 \n",
      "9. click : Reitan etablerer ny bensinstasjonkjede \n",
      "\n",
      "Rank the five candidates for each question based on the user's interest in previously read articles.\n",
      "Question 1) 1: Frykter at Æ sender Rema inn i dødsspiral / 2: Forbrukerrådet advarer mot dorullselger / 3: Dette norske stedet er med på prestisjefylt internasjonal reiseliste / 4: Han kan være Rosenborgs nye ving / 5: Datatilsynet gransker butikkers kundeordninger\n",
      "\n",
      "Do not explain reasons in the response, just return a list of numbers for each article.\n"
     ]
    }
   ],
   "source": [
    "ID = 'U30'\n",
    "\n",
    "history = user[user['User']==ID]['History'].iloc[0]\n",
    "\n",
    "# History에서 News ID 추출\n",
    "news_ids = []\n",
    "[news_ids.append(entry.split(',')[0]) for entry in history.split(';') if entry and entry.split(',')[0] not in news_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "titles = []\n",
    "for news_id in news_ids:\n",
    "    matching_rows = history_news[history_news['News ID'] == news_id]\n",
    "    if not matching_rows.empty:\n",
    "        titles.append(matching_rows.iloc[0]['Title'])\n",
    "        \n",
    "\n",
    "\n",
    "train = user[user['User']==ID]['Train'].iloc[0]\n",
    "\n",
    "# Train에서 News ID 추출\n",
    "train_ids = []\n",
    "[train_ids.append(entry.split(',')[0]) for entry in train.split(';') if entry and entry.split(',')[0] not in train_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "train_titles = []\n",
    "for train_id in train_ids:\n",
    "    matching_rows = train_news[train_news['News ID'] == train_id]\n",
    "    if not matching_rows.empty:\n",
    "        train_titles.append(matching_rows.iloc[0]['Title'])\n",
    "\n",
    "\n",
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_ids = []\n",
    "negative_titles = []\n",
    "used_ids = set(news_ids)  # 중복을 방지하기 위해 사용된 뉴스 ID를 추적\n",
    "\n",
    "for news_id in news_ids:\n",
    "    idx = history_news_sorted[history_news_sorted['News ID'] == news_id].index[0]\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 위에서 가장 가까운 뉴스를 찾기\n",
    "    while above_idx >= 0:\n",
    "        if history_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            break\n",
    "        above_idx -= 1\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 아래에서 가장 가까운 뉴스를 찾기\n",
    "    while below_idx < len(history_news_sorted):\n",
    "        if history_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            break\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_ids.append(similar_ids)\n",
    "    negative_titles.append(similar_titles)\n",
    "\n",
    "\n",
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_train_ids = []\n",
    "negative_train_titles = []\n",
    "used_ids = set(train_ids)  # 중복을 방지하기 위해 used_ids에 train_id를 추가\n",
    "\n",
    "for train_id in train_ids:\n",
    "    idx = train_news_sorted[train_news_sorted['News ID'] == train_id].index[0] \n",
    "    # print(idx)\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # Find the two closest news above, excluding already present news_ids and duplicates\n",
    "    while above_idx >= 0 and len(similar_ids) < 2:\n",
    "        if train_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "        above_idx -= 1\n",
    "\n",
    "    # Find the two closest news below, excluding already present news_ids and duplicates\n",
    "    while below_idx < len(train_news_sorted) and len(similar_ids) < 4:\n",
    "        if train_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_train_ids.append(similar_ids)\n",
    "    negative_train_titles.append(similar_titles)\n",
    "\n",
    "\n",
    "question_ids = [negative_list + [title] for negative_list, title in zip(negative_train_ids, train_ids)]\n",
    "question_titles = [negative_list + [title] for negative_list, title in zip(negative_train_titles, train_titles)]\n",
    "\n",
    "hidden_positions = []\n",
    "\n",
    "# 각 행을 섞고 히든 값의 위치를 저장\n",
    "for row in question_titles:\n",
    "    hidden_value = row[-1]  # 히든 값 (마지막 요소)\n",
    "    random.shuffle(row)  # 전체 행을 섞기\n",
    "    \n",
    "    hidden_index = row.index(hidden_value)  # 히든 값의 새로운 위치 찾기\n",
    "    hidden_positions.append(hidden_index+1)  # 히든 값의 위치 저장\n",
    "\n",
    "\n",
    "number = len(titles)\n",
    "\n",
    "print('[Click History]')\n",
    "for i in range(number):\n",
    "    print(f'{i+1}. click : {titles[i]} ')\n",
    "    \n",
    "print()\n",
    "print(\"Rank the five candidates for each question based on the user's interest in previously read articles.\")\n",
    "\n",
    "for i, titles in enumerate(question_titles):\n",
    "    print(f\"Question {i+1}) \", end=\"\")\n",
    "    for j, title in enumerate(titles):\n",
    "        # print(f\"{j+1}: {title} / \", end=\"\")\n",
    "        if j == len(titles) - 1:\n",
    "            print(f\"{j+1}: {title}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{j+1}: {title} / \", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nDo not explain reasons in the response, just return a list of numbers for each article.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 : Correct\n",
      "\n",
      "총 Correct : 1/1개 (100.000%)\n",
      "평균 오차범위 : 0.000\n"
     ]
    }
   ],
   "source": [
    "questions = input(\"질문을 입력하세요: \")\n",
    "\n",
    "# 질문에서 숫자를 추출\n",
    "def extract_numbers(questions):\n",
    "    # pattern = r\"Question \\d+ : ([\\d, ]+)\"\n",
    "    pattern = r\"Question \\d+: ([\\d, ]+)\"\n",
    "    return [list(map(int, num.split(', '))) for num in re.findall(pattern, questions)]\n",
    "\n",
    "numbers_list = extract_numbers(questions)\n",
    "\n",
    "correct_count = 0\n",
    "total_diff = 0\n",
    "\n",
    "diff_count = 0\n",
    "# 각 질문의 숫자 목록에서 hidden_positions 값의 위치 찾기\n",
    "for i, (hidden, numbers) in enumerate(zip(hidden_positions, numbers_list)):\n",
    "    if numbers[0] == hidden:\n",
    "        print(f\"Question {i + 1} : Correct\")\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        position = numbers.index(hidden)\n",
    "        total_diff += abs(position)\n",
    "        print(f\"Question {i + 1} : {position + 1}\")\n",
    "    diff_count += 1\n",
    "\n",
    "# 결과 요약 출력\n",
    "print(f\"\\n총 Correct : {correct_count}/{len(hidden_positions)}개 ({correct_count / len(hidden_positions):.3%})\")\n",
    "if diff_count > 0:\n",
    "    print(f\"평균 오차범위 : {total_diff / diff_count:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################\n",
      "\n",
      "Question Answer 1 : 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n##########################################\\n\")\n",
    "# 정답\n",
    "for i, label in enumerate(hidden_positions):\n",
    "    print(f\"Question Answer {i+1} : {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coongya11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
