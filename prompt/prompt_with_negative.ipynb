{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "# tsv 파일을 DataFrame으로 읽기\n",
    "user = pd.read_csv('user.tsv', sep='\\t', names=['User', 'History', 'Train', 'Test'])\n",
    "user_raw = pd.read_csv('user(raw).tsv', sep='\\t',  names=['User', 'History', 'Train', 'Test'])\n",
    "\n",
    "history_news = pd.read_csv('history/news.tsv', sep='\\t',  names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "\n",
    "train_news = pd.read_csv('train/news.tsv', sep='\\t', names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "train_behaviors = pd.read_csv('train/behaviors.tsv', sep='\\t', names=['User ID', 'Click time', 'Click history', 'click'])\n",
    "\n",
    "test_news = pd.read_csv('test/news.tsv', sep='\\t', names=['News ID', 'Publish', 'Title', 'Click time history', 'Category'])\n",
    "test_behaviors = pd.read_csv('test/behaviors.tsv', sep='\\t', names=['User ID', 'Click time', 'Click history', 'click'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Publish</th>\n",
       "      <th>Title</th>\n",
       "      <th>Click time history</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N800</td>\n",
       "      <td>2000-11-07 15:29:05</td>\n",
       "      <td>Liker ikke harry navn</td>\n",
       "      <td>2017-01-02 21:54:18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N395</td>\n",
       "      <td>2001-09-10 10:01:11</td>\n",
       "      <td>50 kirkebranner påsatt</td>\n",
       "      <td>2017-01-02 02:14:53</td>\n",
       "      <td>nyheter|innenriks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N117</td>\n",
       "      <td>2001-12-17 13:48:43</td>\n",
       "      <td>- Ringenes Herre er ingen barnefilm</td>\n",
       "      <td>2017-01-01 09:57:07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1393</td>\n",
       "      <td>2002-04-09 15:00:31</td>\n",
       "      <td>Hans Nissens gate</td>\n",
       "      <td>2017-01-04 02:32:32</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N409</td>\n",
       "      <td>2002-05-24 19:33:56</td>\n",
       "      <td>Folkeliv</td>\n",
       "      <td>2017-01-02 02:37:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>N1471</td>\n",
       "      <td>2017-01-03 20:30:00</td>\n",
       "      <td>Kvinner reiser utenlands for å oppfylle babydr...</td>\n",
       "      <td>2017-01-04 06:03:34,2017-01-04 06:37:16,2017-0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>N1464</td>\n",
       "      <td>2017-01-03 20:52:04</td>\n",
       "      <td>- Du skal måke fortauet utenfor huset ditt</td>\n",
       "      <td>2017-01-04 05:54:35,2017-01-04 05:54:36,2017-0...</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>N1469</td>\n",
       "      <td>2017-01-03 20:54:15</td>\n",
       "      <td>Nå blir det flere «klineseter» i kinosalen</td>\n",
       "      <td>2017-01-04 05:59:30,2017-01-04 06:01:12,2017-0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>N1490</td>\n",
       "      <td>2017-01-03 21:39:58</td>\n",
       "      <td>Ladbare hybrider på sterk fremmarsj</td>\n",
       "      <td>2017-01-04 06:42:38,2017-01-04 06:42:41,2017-0...</td>\n",
       "      <td>nyheter|sortrondelag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>N1504</td>\n",
       "      <td>2017-01-03 21:56:31</td>\n",
       "      <td>Henriksen og Diomandes manager sparket</td>\n",
       "      <td>2017-01-04 07:07:49,2017-01-04 07:10:16,2017-0...</td>\n",
       "      <td>100sport|fotball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1516 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     News ID              Publish  \\\n",
       "0       N800  2000-11-07 15:29:05   \n",
       "1       N395  2001-09-10 10:01:11   \n",
       "2       N117  2001-12-17 13:48:43   \n",
       "3      N1393  2002-04-09 15:00:31   \n",
       "4       N409  2002-05-24 19:33:56   \n",
       "...      ...                  ...   \n",
       "1511   N1471  2017-01-03 20:30:00   \n",
       "1512   N1464  2017-01-03 20:52:04   \n",
       "1513   N1469  2017-01-03 20:54:15   \n",
       "1514   N1490  2017-01-03 21:39:58   \n",
       "1515   N1504  2017-01-03 21:56:31   \n",
       "\n",
       "                                                  Title  \\\n",
       "0                                 Liker ikke harry navn   \n",
       "1                                50 kirkebranner påsatt   \n",
       "2                   - Ringenes Herre er ingen barnefilm   \n",
       "3                                     Hans Nissens gate   \n",
       "4                                              Folkeliv   \n",
       "...                                                 ...   \n",
       "1511  Kvinner reiser utenlands for å oppfylle babydr...   \n",
       "1512         - Du skal måke fortauet utenfor huset ditt   \n",
       "1513         Nå blir det flere «klineseter» i kinosalen   \n",
       "1514                Ladbare hybrider på sterk fremmarsj   \n",
       "1515             Henriksen og Diomandes manager sparket   \n",
       "\n",
       "                                     Click time history              Category  \n",
       "0                                   2017-01-02 21:54:18                   NaN  \n",
       "1                                   2017-01-02 02:14:53     nyheter|innenriks  \n",
       "2                                   2017-01-01 09:57:07                   NaN  \n",
       "3                                   2017-01-04 02:32:32     nyheter|trondheim  \n",
       "4                                   2017-01-02 02:37:05                   NaN  \n",
       "...                                                 ...                   ...  \n",
       "1511  2017-01-04 06:03:34,2017-01-04 06:37:16,2017-0...                   NaN  \n",
       "1512  2017-01-04 05:54:35,2017-01-04 05:54:36,2017-0...     nyheter|trondheim  \n",
       "1513  2017-01-04 05:59:30,2017-01-04 06:01:12,2017-0...                   NaN  \n",
       "1514  2017-01-04 06:42:38,2017-01-04 06:42:41,2017-0...  nyheter|sortrondelag  \n",
       "1515  2017-01-04 07:07:49,2017-01-04 07:10:16,2017-0...      100sport|fotball  \n",
       "\n",
       "[1516 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# publish 순서에 맞게 오름차순으로 정렬\n",
    "history_news_sorted = history_news.sort_values(by='Publish', ascending=True).reset_index(drop=True)\n",
    "history_news_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Publish</th>\n",
       "      <th>Title</th>\n",
       "      <th>Click time history</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N2609</td>\n",
       "      <td>2001-02-16 23:00:00</td>\n",
       "      <td>Thalliumdrapene på Ranheim</td>\n",
       "      <td>2017-01-05 21:34:07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2256</td>\n",
       "      <td>2001-07-10 06:39:42</td>\n",
       "      <td>Tropenatt under åpen himmel</td>\n",
       "      <td>2017-01-05 04:53:20</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2699</td>\n",
       "      <td>2001-11-05 08:21:56</td>\n",
       "      <td>Paul Fjermstads veg</td>\n",
       "      <td>2017-01-05 23:19:54</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3476</td>\n",
       "      <td>2002-05-03 06:38:09</td>\n",
       "      <td>Kriminelle vil inn i Bandidos</td>\n",
       "      <td>2017-01-07 05:37:13</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N2689</td>\n",
       "      <td>2002-05-23 09:55:36</td>\n",
       "      <td>Harald Bothners veg</td>\n",
       "      <td>2017-01-05 23:16:24</td>\n",
       "      <td>nyheter|trondheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>N3497</td>\n",
       "      <td>2017-01-06 20:38:25</td>\n",
       "      <td>Politiet håper obduksjonen vil gi svar på døds...</td>\n",
       "      <td>2017-01-07 06:42:10,2017-01-07 06:48:12</td>\n",
       "      <td>nyheter|innenriks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>N3504</td>\n",
       "      <td>2017-01-06 21:51:55</td>\n",
       "      <td>Fryktelig høyt, men ingen katastrofe</td>\n",
       "      <td>2017-01-07 06:57:42,2017-01-07 06:59:37,2017-0...</td>\n",
       "      <td>pluss|meninger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>N3519</td>\n",
       "      <td>2017-01-06 22:13:16</td>\n",
       "      <td>De flinkeste elevene må stort sett klare seg selv</td>\n",
       "      <td>2017-01-07 07:22:31,2017-01-07 07:23:17,2017-0...</td>\n",
       "      <td>pluss|meninger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>N3517</td>\n",
       "      <td>2017-01-06 22:14:41</td>\n",
       "      <td>En nasjonal ulykke</td>\n",
       "      <td>2017-01-07 07:21:04,2017-01-07 07:24:36,2017-0...</td>\n",
       "      <td>pluss|kultur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>N3518</td>\n",
       "      <td>2017-01-06 22:14:44</td>\n",
       "      <td>Hva er vitsen med å bo i Norge hvis man hater ...</td>\n",
       "      <td>2017-01-07 07:21:32,2017-01-07 07:23:25,2017-0...</td>\n",
       "      <td>pluss|meninger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2020 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     News ID              Publish  \\\n",
       "0      N2609  2001-02-16 23:00:00   \n",
       "1      N2256  2001-07-10 06:39:42   \n",
       "2      N2699  2001-11-05 08:21:56   \n",
       "3      N3476  2002-05-03 06:38:09   \n",
       "4      N2689  2002-05-23 09:55:36   \n",
       "...      ...                  ...   \n",
       "2015   N3497  2017-01-06 20:38:25   \n",
       "2016   N3504  2017-01-06 21:51:55   \n",
       "2017   N3519  2017-01-06 22:13:16   \n",
       "2018   N3517  2017-01-06 22:14:41   \n",
       "2019   N3518  2017-01-06 22:14:44   \n",
       "\n",
       "                                                  Title  \\\n",
       "0                            Thalliumdrapene på Ranheim   \n",
       "1                           Tropenatt under åpen himmel   \n",
       "2                                   Paul Fjermstads veg   \n",
       "3                         Kriminelle vil inn i Bandidos   \n",
       "4                                   Harald Bothners veg   \n",
       "...                                                 ...   \n",
       "2015  Politiet håper obduksjonen vil gi svar på døds...   \n",
       "2016               Fryktelig høyt, men ingen katastrofe   \n",
       "2017  De flinkeste elevene må stort sett klare seg selv   \n",
       "2018                                 En nasjonal ulykke   \n",
       "2019  Hva er vitsen med å bo i Norge hvis man hater ...   \n",
       "\n",
       "                                     Click time history           Category  \n",
       "0                                   2017-01-05 21:34:07                NaN  \n",
       "1                                   2017-01-05 04:53:20  nyheter|trondheim  \n",
       "2                                   2017-01-05 23:19:54  nyheter|trondheim  \n",
       "3                                   2017-01-07 05:37:13  nyheter|trondheim  \n",
       "4                                   2017-01-05 23:16:24  nyheter|trondheim  \n",
       "...                                                 ...                ...  \n",
       "2015            2017-01-07 06:42:10,2017-01-07 06:48:12  nyheter|innenriks  \n",
       "2016  2017-01-07 06:57:42,2017-01-07 06:59:37,2017-0...     pluss|meninger  \n",
       "2017  2017-01-07 07:22:31,2017-01-07 07:23:17,2017-0...     pluss|meninger  \n",
       "2018  2017-01-07 07:21:04,2017-01-07 07:24:36,2017-0...       pluss|kultur  \n",
       "2019  2017-01-07 07:21:32,2017-01-07 07:23:25,2017-0...     pluss|meninger  \n",
       "\n",
       "[2020 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# publish 순서에 맞게 오름차순으로 정렬\n",
    "train_news_sorted = train_news.sort_values(by='Publish', ascending=True).reset_index(drop=True)\n",
    "train_news_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User의 history,train news title 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N1', 'N3', 'N98', 'N329', 'N15', 'N385', 'N817', 'N831', 'N868', 'N982', 'N979', 'N898', 'N1031', 'N785', 'N1057', 'N1092']\n",
      "16\n",
      "['Se lesernes nyttårsbilder', '- Det blir fyrverkeri', 'Startet det nye året med fyrverkerishow', 'Fire kjørt til sykehus', 'Hvem syns du er Årets trønder?', 'Norges landslagssjef ville ha russisk leder utestengt', 'Vil du bli sprekere i 2017? Eksperten har et klart råd', 'Intens pengejakt pågår nå for å få skiheltene til Trondheim', 'Politiet frigir navn på kvinne som døde etter E39-ulykke', '- Dette er ikke Senterpartiets olje- og gasspolitikk', 'Ola Borten Moe og Ivar Vigdenes påstår at det foregår en avkristning av Norge som rektorer, politikere, ateister og humanetikere står bak?Er det sant?', 'Sørloth ville ha sagt nei om Rosenborg kom på banen i dag', 'Kokt kujur til middag', 'Slik bor Trondheims «Anno»-deltagere', '- Helt ufattelig at det går an å behandle en ny bil på denne måten', '- Helt greit hvis bensinprisen blir 19-20 kroner']\n",
      "16\n",
      "['N2105', 'N2172', 'N2094', 'N1817', 'N1813', 'N2337', 'N3197']\n",
      "7\n",
      "['Æ-en ble en nedtur', 'Rælingen - Byåsen', 'Iversen varslet legen tre dager før kollapsen', 'Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut', '10 spådommer for fysisk aktivitet i fremtiden', 'Å si at kristne julesanger fjernes, er tøv', 'Nils Arne Eggen: - Akkurat nå bruker jeg gåstol og krykker']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "ID = 'U2'\n",
    "\n",
    "history = user[user['User']==ID]['History'].iloc[0]\n",
    "\n",
    "# History에서 News ID 추출\n",
    "news_ids = []\n",
    "[news_ids.append(entry.split(',')[0]) for entry in history.split(';') if entry and entry.split(',')[0] not in news_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "titles = []\n",
    "for news_id in news_ids:\n",
    "    matching_rows = history_news[history_news['News ID'] == news_id]\n",
    "    if not matching_rows.empty:\n",
    "        titles.append(matching_rows.iloc[0]['Title'])\n",
    "        \n",
    "\n",
    "\n",
    "train = user[user['User']==ID]['Train'].iloc[0]\n",
    "\n",
    "# Train에서 News ID 추출\n",
    "train_ids = []\n",
    "[train_ids.append(entry.split(',')[0]) for entry in train.split(';') if entry and entry.split(',')[0] not in train_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "train_titles = []\n",
    "for train_id in train_ids:\n",
    "    matching_rows = train_news[train_news['News ID'] == train_id]\n",
    "    if not matching_rows.empty:\n",
    "        train_titles.append(matching_rows.iloc[0]['Title'])\n",
    "\n",
    "\n",
    "print(news_ids)\n",
    "print(len(news_ids))\n",
    "\n",
    "print(titles) \n",
    "print(len(titles))\n",
    "\n",
    "print(train_ids) \n",
    "print(len(train_ids))\n",
    "\n",
    "print(train_titles) \n",
    "print(len(train_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative News 추출 (History News) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N596', 'N2'], ['N653', 'N598'], ['N148', 'N1402'], ['N333', 'N335'], ['N1001', 'N566'], ['N426', 'N387'], ['N783', 'N829'], ['N839', 'N830'], ['N843', 'N874'], ['N981', 'N999'], ['N933', 'N1006'], ['N905', 'N902'], ['N927', 'N1032'], ['N101', 'N943'], ['N1053', 'N1066'], ['N1097', 'N1098']]\n",
      "[['Måtte i oppvaskmøte etter å ha kritisert landslaget', 'Her koker det over for Tønseth. Så stakk han fra stadion i sinne.'], ['Russer viste monsterkrefter: - Noe av det råeste jeg har sett', 'Lurt av appen'], ['Nødbluss sendt gjennom vindu startet branntilløp', 'Mann hang fast etter bil i Verdal'], ['Norsk seier i nyttårshopprennet: - For en prestasjon', 'Her laver snøen ned'], ['Klopp om rivalen: - En fantastisk og innflytelsesrik manager', 'Japansk gutt drepte sin mor med hammer og kniv'], ['Prøvekjørt: Skoda Superb. Plassmesteren', 'Færre fyrverkeriskader enn tidligere'], ['Frontkollisjon på Heimdal', 'Vi må bli mer som Marvin'], ['Hund ville ikke bruke genser – bet tre personer', 'Nå er navnet frigitt etter dødsfall i Gjemnes'], ['Nå er RBK-floppen legende i Australia', 'I kveld kan du få et spesielt syn på himmelen'], ['- Fast ansatte er et konkurransefortrinn', 'Med kreative grep har Øystein fått et ganske så unikt hjem'], ['Slik gikk det da elbilene måtte betale p-avgift', 'Sjefen må bremse de norske Tour-favorittene'], ['Så viktige er bevegelsene fra babyen i magen', 'Tidligere Tromsø-keeper tvinges til å legge opp etter bisarr kjøkkenskade'], ['Victor er spansk skiturist i Bymarka: - I Spania er det altfor varmt', '- Svært trist at antallet trafikkdrepte igjen har økt'], ['- Vi har ikke penger til nye klær og julegaver til barna', 'Svein Børge ble far mens han lå i koma etter brannen'], ['- Det er fullt mulig å blande norsk og samisk i en tale', 'Tande har aldri sett forbildet i aksjon: - Fikk høre historiene på museum'], ['-«Anno» er tro mot historien', 'Vil kreve erstatning etter båtkrasj']]\n"
     ]
    }
   ],
   "source": [
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_ids = []\n",
    "negative_titles = []\n",
    "used_ids = set(news_ids)  # 중복을 방지하기 위해 사용된 뉴스 ID를 추적\n",
    "\n",
    "for news_id in news_ids:\n",
    "    idx = history_news_sorted[history_news_sorted['News ID'] == news_id].index[0]\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 위에서 가장 가까운 뉴스를 찾기\n",
    "    while above_idx >= 0:\n",
    "        if history_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            break\n",
    "        above_idx -= 1\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 아래에서 가장 가까운 뉴스를 찾기\n",
    "    while below_idx < len(history_news_sorted):\n",
    "        if history_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            break\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_ids.append(similar_ids)\n",
    "    negative_titles.append(similar_titles)\n",
    "\n",
    "\n",
    "print(negative_ids)  \n",
    "print(negative_titles)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative News 추출 (Question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N2094', 'N2172', 'N2105', 'N2337', 'N1817', 'N3197', 'N1813'}\n",
      "[['N2097', 'N2175', 'N2118', 'N2125'], ['N1572', 'N1587', 'N1535', 'N1530'], ['N2093', 'N2077', 'N2160', 'N2163'], ['N1804', 'N1808', 'N1806', 'N1845'], ['N2080', 'N1973', 'N3344', 'N2886'], ['N2333', 'N2313', 'N2387', 'N2458'], ['N3184', 'N3183', 'N3220', 'N3201']]\n",
      "[['RBK-unggutter på vei bort fra Lerkendal', 'Trafikkuhell i Elgesetergate', 'Gråtende Weng ba om unnskyldning til lagvenninnen', 'Advokat klager på henleggelsen av Drevland-saken'], ['Nå kommer de nye fotoboksene', 'Fant ikke spor av gift etter dødelig dose', '- Jeg fikk svingt unna i siste liten', 'Apollo kutter ut charterturer til Tyrkia'], ['Norsk sjef tror Ustjugov kan dominere i 10 år', 'Utrolig, sann historie om bortkommen 5-åring i India', 'John Carew fronter e-post som truer kundene med gebyr: - Dette er ulovlig', 'Bob Bradley i Oslo. Bekrefter møte med NFF'], ['Disse vil bli lensmann i Meråker og Frosta', 'Ungdom får tilbake førerkort for å bli yrkessjåfør', 'Saktegående trafikk i Moholtlia', 'Vurderer å flytte fra Midtbyen'], ['Er du Joker-millionæren fra Aure?', '- Målet er å finne trønderske artister som kan fylle Sverresborg', 'Tonje (20) kan sende forbildet på benken', 'Olav har fjernet begge nyrene - nå renser han blodet sitt i stua'], ['-Jeg er 90 prosent sikker på at valpen min er tatt av ulv', 'Ordfører går i rette med kommunaldirektør om NTNU-campus', 'Fant amfetamin på hotellrom i Trondheim', 'Mann pågrepet og tyvegods funnet etter innbrudd i Midtbyen og Byåsen'], ['Får ikke satt ned fartsgrense', 'Lensmannskontoret nedlagt', 'Norske Bianca Wessel bor i et «fuglerede» i 28. etasje midt i tykkeste London', 'I det rike USA er dødeligheten for kvinner i den hvite middelklassen nå økende']]\n"
     ]
    }
   ],
   "source": [
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_train_ids = []\n",
    "negative_train_titles = []\n",
    "used_ids = set(train_ids)  # 중복을 방지하기 위해 used_ids에 train_id를 추가\n",
    "print(used_ids)\n",
    "\n",
    "for train_id in train_ids:\n",
    "    idx = train_news_sorted[train_news_sorted['News ID'] == train_id].index[0] \n",
    "    # print(idx)\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # 이미 존재하는 News ID와 중복된 News를 제외하고 위에서 가장 가까운 두 개의 News를 find\n",
    "    while above_idx >= 0 and len(similar_ids) < 2:\n",
    "        if train_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "        above_idx -= 1\n",
    "\n",
    "    # 이미 존재하는 News ID와 중복된 News를 제외하고 아래에서 가장 가까운 두 개의 News를 find\n",
    "    while below_idx < len(train_news_sorted) and len(similar_ids) < 4:\n",
    "        if train_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_train_ids.append(similar_ids)\n",
    "    negative_train_titles.append(similar_titles)\n",
    "\n",
    "# train_ids에 대한 유사한 뉴스 ID 및 제목의 결과 목록\n",
    "print(negative_train_ids)  # List of news IDs\n",
    "print(negative_train_titles)  # List of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N2105', 'N2172', 'N2094', 'N1817', 'N1813', 'N2337', 'N3197']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N2097', 'N2175', 'N2118', 'N2125', 'N2105'], ['N1572', 'N1587', 'N1535', 'N1530', 'N2172'], ['N2093', 'N2077', 'N2160', 'N2163', 'N2094'], ['N1804', 'N1808', 'N1806', 'N1845', 'N1817'], ['N2080', 'N1973', 'N3344', 'N2886', 'N1813'], ['N2333', 'N2313', 'N2387', 'N2458', 'N2337'], ['N3184', 'N3183', 'N3220', 'N3201', 'N3197']]\n",
      "[['RBK-unggutter på vei bort fra Lerkendal', 'Trafikkuhell i Elgesetergate', 'Gråtende Weng ba om unnskyldning til lagvenninnen', 'Advokat klager på henleggelsen av Drevland-saken', 'Æ-en ble en nedtur'], ['Nå kommer de nye fotoboksene', 'Fant ikke spor av gift etter dødelig dose', '- Jeg fikk svingt unna i siste liten', 'Apollo kutter ut charterturer til Tyrkia', 'Rælingen - Byåsen'], ['Norsk sjef tror Ustjugov kan dominere i 10 år', 'Utrolig, sann historie om bortkommen 5-åring i India', 'John Carew fronter e-post som truer kundene med gebyr: - Dette er ulovlig', 'Bob Bradley i Oslo. Bekrefter møte med NFF', 'Iversen varslet legen tre dager før kollapsen'], ['Disse vil bli lensmann i Meråker og Frosta', 'Ungdom får tilbake førerkort for å bli yrkessjåfør', 'Saktegående trafikk i Moholtlia', 'Vurderer å flytte fra Midtbyen', 'Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut'], ['Er du Joker-millionæren fra Aure?', '- Målet er å finne trønderske artister som kan fylle Sverresborg', 'Tonje (20) kan sende forbildet på benken', 'Olav har fjernet begge nyrene - nå renser han blodet sitt i stua', '10 spådommer for fysisk aktivitet i fremtiden'], ['-Jeg er 90 prosent sikker på at valpen min er tatt av ulv', 'Ordfører går i rette med kommunaldirektør om NTNU-campus', 'Fant amfetamin på hotellrom i Trondheim', 'Mann pågrepet og tyvegods funnet etter innbrudd i Midtbyen og Byåsen', 'Å si at kristne julesanger fjernes, er tøv'], ['Får ikke satt ned fartsgrense', 'Lensmannskontoret nedlagt', 'Norske Bianca Wessel bor i et «fuglerede» i 28. etasje midt i tykkeste London', 'I det rike USA er dødeligheten for kvinner i den hvite middelklassen nå økende', 'Nils Arne Eggen: - Akkurat nå bruker jeg gåstol og krykker']]\n",
      "\n",
      "Shuffled Question IDs: [['Trafikkuhell i Elgesetergate', 'Advokat klager på henleggelsen av Drevland-saken', 'Gråtende Weng ba om unnskyldning til lagvenninnen', 'Æ-en ble en nedtur', 'RBK-unggutter på vei bort fra Lerkendal'], ['Fant ikke spor av gift etter dødelig dose', 'Rælingen - Byåsen', 'Apollo kutter ut charterturer til Tyrkia', '- Jeg fikk svingt unna i siste liten', 'Nå kommer de nye fotoboksene'], ['Iversen varslet legen tre dager før kollapsen', 'John Carew fronter e-post som truer kundene med gebyr: - Dette er ulovlig', 'Norsk sjef tror Ustjugov kan dominere i 10 år', 'Utrolig, sann historie om bortkommen 5-åring i India', 'Bob Bradley i Oslo. Bekrefter møte med NFF'], ['Saktegående trafikk i Moholtlia', 'Ungdom får tilbake førerkort for å bli yrkessjåfør', 'Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut', 'Disse vil bli lensmann i Meråker og Frosta', 'Vurderer å flytte fra Midtbyen'], ['- Målet er å finne trønderske artister som kan fylle Sverresborg', 'Olav har fjernet begge nyrene - nå renser han blodet sitt i stua', 'Er du Joker-millionæren fra Aure?', '10 spådommer for fysisk aktivitet i fremtiden', 'Tonje (20) kan sende forbildet på benken'], ['Mann pågrepet og tyvegods funnet etter innbrudd i Midtbyen og Byåsen', '-Jeg er 90 prosent sikker på at valpen min er tatt av ulv', 'Ordfører går i rette med kommunaldirektør om NTNU-campus', 'Fant amfetamin på hotellrom i Trondheim', 'Å si at kristne julesanger fjernes, er tøv'], ['Får ikke satt ned fartsgrense', 'Lensmannskontoret nedlagt', 'Norske Bianca Wessel bor i et «fuglerede» i 28. etasje midt i tykkeste London', 'I det rike USA er dødeligheten for kvinner i den hvite middelklassen nå økende', 'Nils Arne Eggen: - Akkurat nå bruker jeg gåstol og krykker']]\n",
      "Hidden Positions: [4, 2, 1, 3, 4, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "question_ids = [negative_list + [title] for negative_list, title in zip(negative_train_ids, train_ids)]\n",
    "question_titles = [negative_list + [title] for negative_list, title in zip(negative_train_titles, train_titles)]\n",
    "\n",
    "print(question_ids)\n",
    "print(question_titles)\n",
    "print()\n",
    "\n",
    "hidden_positions = []\n",
    "\n",
    "# 각 행을 섞고 히든 값의 위치를 저장\n",
    "for row in question_titles:\n",
    "    hidden_value = row[-1]  # 히든 값 (마지막 요소)\n",
    "    random.shuffle(row)  # 전체 행을 섞기\n",
    "    \n",
    "    hidden_index = row.index(hidden_value)  # 히든 값의 새로운 위치 찾기\n",
    "    hidden_positions.append(hidden_index+1)  # 히든 값의 위치 저장\n",
    "\n",
    "print(\"Shuffled Question IDs:\", question_titles)\n",
    "print(\"Hidden Positions:\", hidden_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive & Negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Click History]\n",
      "1. click : Se lesernes nyttårsbilder / non-click_1: Måtte i oppvaskmøte etter å ha kritisert landslaget, non-click_2: Her koker det over for Tønseth. Så stakk han fra stadion i sinne.\n",
      "2. click : - Det blir fyrverkeri / non-click_1: Russer viste monsterkrefter: - Noe av det råeste jeg har sett, non-click_2: Lurt av appen\n",
      "3. click : Startet det nye året med fyrverkerishow / non-click_1: Nødbluss sendt gjennom vindu startet branntilløp, non-click_2: Mann hang fast etter bil i Verdal\n",
      "4. click : Fire kjørt til sykehus / non-click_1: Norsk seier i nyttårshopprennet: - For en prestasjon, non-click_2: Her laver snøen ned\n",
      "5. click : Hvem syns du er Årets trønder? / non-click_1: Klopp om rivalen: - En fantastisk og innflytelsesrik manager, non-click_2: Japansk gutt drepte sin mor med hammer og kniv\n",
      "6. click : Norges landslagssjef ville ha russisk leder utestengt / non-click_1: Prøvekjørt: Skoda Superb. Plassmesteren, non-click_2: Færre fyrverkeriskader enn tidligere\n",
      "7. click : Vil du bli sprekere i 2017? Eksperten har et klart råd / non-click_1: Frontkollisjon på Heimdal, non-click_2: Vi må bli mer som Marvin\n",
      "8. click : Intens pengejakt pågår nå for å få skiheltene til Trondheim / non-click_1: Hund ville ikke bruke genser – bet tre personer, non-click_2: Nå er navnet frigitt etter dødsfall i Gjemnes\n",
      "9. click : Politiet frigir navn på kvinne som døde etter E39-ulykke / non-click_1: Nå er RBK-floppen legende i Australia, non-click_2: I kveld kan du få et spesielt syn på himmelen\n",
      "10. click : - Dette er ikke Senterpartiets olje- og gasspolitikk / non-click_1: - Fast ansatte er et konkurransefortrinn, non-click_2: Med kreative grep har Øystein fått et ganske så unikt hjem\n",
      "11. click : Ola Borten Moe og Ivar Vigdenes påstår at det foregår en avkristning av Norge som rektorer, politikere, ateister og humanetikere står bak?Er det sant? / non-click_1: Slik gikk det da elbilene måtte betale p-avgift, non-click_2: Sjefen må bremse de norske Tour-favorittene\n",
      "12. click : Sørloth ville ha sagt nei om Rosenborg kom på banen i dag / non-click_1: Så viktige er bevegelsene fra babyen i magen, non-click_2: Tidligere Tromsø-keeper tvinges til å legge opp etter bisarr kjøkkenskade\n",
      "13. click : Kokt kujur til middag / non-click_1: Victor er spansk skiturist i Bymarka: - I Spania er det altfor varmt, non-click_2: - Svært trist at antallet trafikkdrepte igjen har økt\n",
      "14. click : Slik bor Trondheims «Anno»-deltagere / non-click_1: - Vi har ikke penger til nye klær og julegaver til barna, non-click_2: Svein Børge ble far mens han lå i koma etter brannen\n",
      "15. click : - Helt ufattelig at det går an å behandle en ny bil på denne måten / non-click_1: - Det er fullt mulig å blande norsk og samisk i en tale, non-click_2: Tande har aldri sett forbildet i aksjon: - Fikk høre historiene på museum\n",
      "16. click : - Helt greit hvis bensinprisen blir 19-20 kroner / non-click_1: -«Anno» er tro mot historien, non-click_2: Vil kreve erstatning etter båtkrasj\n",
      "\n",
      "Rank the five candidates for each question based on the user's interest in previously read articles.\n",
      "Question 1) 1: Trafikkuhell i Elgesetergate / 2: Advokat klager på henleggelsen av Drevland-saken / 3: Gråtende Weng ba om unnskyldning til lagvenninnen / 4: Æ-en ble en nedtur / 5: RBK-unggutter på vei bort fra Lerkendal\n",
      "Question 2) 1: Fant ikke spor av gift etter dødelig dose / 2: Rælingen - Byåsen / 3: Apollo kutter ut charterturer til Tyrkia / 4: - Jeg fikk svingt unna i siste liten / 5: Nå kommer de nye fotoboksene\n",
      "Question 3) 1: Iversen varslet legen tre dager før kollapsen / 2: John Carew fronter e-post som truer kundene med gebyr: - Dette er ulovlig / 3: Norsk sjef tror Ustjugov kan dominere i 10 år / 4: Utrolig, sann historie om bortkommen 5-åring i India / 5: Bob Bradley i Oslo. Bekrefter møte med NFF\n",
      "Question 4) 1: Saktegående trafikk i Moholtlia / 2: Ungdom får tilbake førerkort for å bli yrkessjåfør / 3: Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut / 4: Disse vil bli lensmann i Meråker og Frosta / 5: Vurderer å flytte fra Midtbyen\n",
      "Question 5) 1: - Målet er å finne trønderske artister som kan fylle Sverresborg / 2: Olav har fjernet begge nyrene - nå renser han blodet sitt i stua / 3: Er du Joker-millionæren fra Aure? / 4: 10 spådommer for fysisk aktivitet i fremtiden / 5: Tonje (20) kan sende forbildet på benken\n",
      "Question 6) 1: Mann pågrepet og tyvegods funnet etter innbrudd i Midtbyen og Byåsen / 2: -Jeg er 90 prosent sikker på at valpen min er tatt av ulv / 3: Ordfører går i rette med kommunaldirektør om NTNU-campus / 4: Fant amfetamin på hotellrom i Trondheim / 5: Å si at kristne julesanger fjernes, er tøv\n",
      "Question 7) 1: Får ikke satt ned fartsgrense / 2: Lensmannskontoret nedlagt / 3: Norske Bianca Wessel bor i et «fuglerede» i 28. etasje midt i tykkeste London / 4: I det rike USA er dødeligheten for kvinner i den hvite middelklassen nå økende / 5: Nils Arne Eggen: - Akkurat nå bruker jeg gåstol og krykker\n",
      "\n",
      "Do not explain reasons in the response, just return a list of numbers for each article.\n"
     ]
    }
   ],
   "source": [
    "number = len(titles)\n",
    "\n",
    "print('[Click History]')\n",
    "for i in range(number):\n",
    "    print(f'{i+1}. click : {titles[i]} / non-click_1: {negative_titles[i][0]}, non-click_2: {negative_titles[i][1]}')\n",
    "    \n",
    "print()\n",
    "print(\"Rank the five candidates for each question based on the user's interest in previously read articles.\")\n",
    "\n",
    "for i, titles in enumerate(question_titles):\n",
    "    print(f\"Question {i+1}) \", end=\"\")\n",
    "    for j, title in enumerate(titles):\n",
    "        # print(f\"{j+1}: {title} / \", end=\"\")\n",
    "        if j == len(titles) - 1:\n",
    "            print(f\"{j+1}: {title}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{j+1}: {title} / \", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nDo not explain reasons in the response, just return a list of numbers for each article.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Positions: [4, 2, 1, 3, 4, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# 정답\n",
    "print(\"Hidden Positions:\", hidden_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한번에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Click History]\n",
      "1. click : Se lesernes nyttårsbilder / non-click_1: Måtte i oppvaskmøte etter å ha kritisert landslaget, non-click_2: Her koker det over for Tønseth. Så stakk han fra stadion i sinne.\n",
      "2. click : - Det blir fyrverkeri / non-click_1: Russer viste monsterkrefter: - Noe av det råeste jeg har sett, non-click_2: Lurt av appen\n",
      "3. click : Startet det nye året med fyrverkerishow / non-click_1: Nødbluss sendt gjennom vindu startet branntilløp, non-click_2: Mann hang fast etter bil i Verdal\n",
      "4. click : Fire kjørt til sykehus / non-click_1: Norsk seier i nyttårshopprennet: - For en prestasjon, non-click_2: Her laver snøen ned\n",
      "5. click : Hvem syns du er Årets trønder? / non-click_1: Klopp om rivalen: - En fantastisk og innflytelsesrik manager, non-click_2: Japansk gutt drepte sin mor med hammer og kniv\n",
      "6. click : Norges landslagssjef ville ha russisk leder utestengt / non-click_1: Prøvekjørt: Skoda Superb. Plassmesteren, non-click_2: Færre fyrverkeriskader enn tidligere\n",
      "7. click : Vil du bli sprekere i 2017? Eksperten har et klart råd / non-click_1: Frontkollisjon på Heimdal, non-click_2: Vi må bli mer som Marvin\n",
      "8. click : Intens pengejakt pågår nå for å få skiheltene til Trondheim / non-click_1: Hund ville ikke bruke genser – bet tre personer, non-click_2: Nå er navnet frigitt etter dødsfall i Gjemnes\n",
      "9. click : Politiet frigir navn på kvinne som døde etter E39-ulykke / non-click_1: Nå er RBK-floppen legende i Australia, non-click_2: I kveld kan du få et spesielt syn på himmelen\n",
      "10. click : - Dette er ikke Senterpartiets olje- og gasspolitikk / non-click_1: - Fast ansatte er et konkurransefortrinn, non-click_2: Med kreative grep har Øystein fått et ganske så unikt hjem\n",
      "11. click : Ola Borten Moe og Ivar Vigdenes påstår at det foregår en avkristning av Norge som rektorer, politikere, ateister og humanetikere står bak?Er det sant? / non-click_1: Slik gikk det da elbilene måtte betale p-avgift, non-click_2: Sjefen må bremse de norske Tour-favorittene\n",
      "12. click : Sørloth ville ha sagt nei om Rosenborg kom på banen i dag / non-click_1: Så viktige er bevegelsene fra babyen i magen, non-click_2: Tidligere Tromsø-keeper tvinges til å legge opp etter bisarr kjøkkenskade\n",
      "13. click : Kokt kujur til middag / non-click_1: Victor er spansk skiturist i Bymarka: - I Spania er det altfor varmt, non-click_2: - Svært trist at antallet trafikkdrepte igjen har økt\n",
      "14. click : Slik bor Trondheims «Anno»-deltagere / non-click_1: - Vi har ikke penger til nye klær og julegaver til barna, non-click_2: Svein Børge ble far mens han lå i koma etter brannen\n",
      "15. click : - Helt ufattelig at det går an å behandle en ny bil på denne måten / non-click_1: - Det er fullt mulig å blande norsk og samisk i en tale, non-click_2: Tande har aldri sett forbildet i aksjon: - Fikk høre historiene på museum\n",
      "16. click : - Helt greit hvis bensinprisen blir 19-20 kroner / non-click_1: -«Anno» er tro mot historien, non-click_2: Vil kreve erstatning etter båtkrasj\n",
      "\n",
      "Rank the five candidates for each question based on the user's interest in previously read articles.\n",
      "Question 1) 1: Advokat klager på henleggelsen av Drevland-saken / 2: Æ-en ble en nedtur / 3: Trafikkuhell i Elgesetergate / 4: RBK-unggutter på vei bort fra Lerkendal / 5: Gråtende Weng ba om unnskyldning til lagvenninnen\n",
      "Question 2) 1: Nå kommer de nye fotoboksene / 2: Fant ikke spor av gift etter dødelig dose / 3: - Jeg fikk svingt unna i siste liten / 4: Apollo kutter ut charterturer til Tyrkia / 5: Rælingen - Byåsen\n",
      "Question 3) 1: Bob Bradley i Oslo. Bekrefter møte med NFF / 2: Iversen varslet legen tre dager før kollapsen / 3: John Carew fronter e-post som truer kundene med gebyr: - Dette er ulovlig / 4: Utrolig, sann historie om bortkommen 5-åring i India / 5: Norsk sjef tror Ustjugov kan dominere i 10 år\n",
      "Question 4) 1: Ungdom får tilbake førerkort for å bli yrkessjåfør / 2: Vurderer å flytte fra Midtbyen / 3: Disse vil bli lensmann i Meråker og Frosta / 4: Saktegående trafikk i Moholtlia / 5: Ekspert: – Om du vil ned i vekt, er dette det første jeg anbefaler å kutte ut\n",
      "Question 5) 1: 10 spådommer for fysisk aktivitet i fremtiden / 2: - Målet er å finne trønderske artister som kan fylle Sverresborg / 3: Er du Joker-millionæren fra Aure? / 4: Olav har fjernet begge nyrene - nå renser han blodet sitt i stua / 5: Tonje (20) kan sende forbildet på benken\n",
      "Question 6) 1: Ordfører går i rette med kommunaldirektør om NTNU-campus / 2: Mann pågrepet og tyvegods funnet etter innbrudd i Midtbyen og Byåsen / 3: Fant amfetamin på hotellrom i Trondheim / 4: Å si at kristne julesanger fjernes, er tøv / 5: -Jeg er 90 prosent sikker på at valpen min er tatt av ulv\n",
      "Question 7) 1: Norske Bianca Wessel bor i et «fuglerede» i 28. etasje midt i tykkeste London / 2: Får ikke satt ned fartsgrense / 3: Nils Arne Eggen: - Akkurat nå bruker jeg gåstol og krykker / 4: I det rike USA er dødeligheten for kvinner i den hvite middelklassen nå økende / 5: Lensmannskontoret nedlagt\n",
      "\n",
      "Do not explain reasons in the response, just return a list of numbers for each article.\n"
     ]
    }
   ],
   "source": [
    "ID = 'U2'\n",
    "\n",
    "history = user[user['User']==ID]['History'].iloc[0]\n",
    "\n",
    "# History에서 News ID 추출\n",
    "news_ids = []\n",
    "[news_ids.append(entry.split(',')[0]) for entry in history.split(';') if entry and entry.split(',')[0] not in news_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "titles = []\n",
    "for news_id in news_ids:\n",
    "    matching_rows = history_news[history_news['News ID'] == news_id]\n",
    "    if not matching_rows.empty:\n",
    "        titles.append(matching_rows.iloc[0]['Title'])\n",
    "        \n",
    "\n",
    "\n",
    "train = user[user['User']==ID]['Train'].iloc[0]\n",
    "\n",
    "# Train에서 News ID 추출\n",
    "train_ids = []\n",
    "[train_ids.append(entry.split(',')[0]) for entry in train.split(';') if entry and entry.split(',')[0] not in train_ids]\n",
    "\n",
    "# News ID의 맞는 Title 추출\n",
    "train_titles = []\n",
    "for train_id in train_ids:\n",
    "    matching_rows = train_news[train_news['News ID'] == train_id]\n",
    "    if not matching_rows.empty:\n",
    "        train_titles.append(matching_rows.iloc[0]['Title'])\n",
    "\n",
    "\n",
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_ids = []\n",
    "negative_titles = []\n",
    "used_ids = set(news_ids)  # 중복을 방지하기 위해 사용된 뉴스 ID를 추적\n",
    "\n",
    "for news_id in news_ids:\n",
    "    idx = history_news_sorted[history_news_sorted['News ID'] == news_id].index[0]\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 위에서 가장 가까운 뉴스를 찾기\n",
    "    while above_idx >= 0:\n",
    "        if history_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[above_idx, 'News ID'])\n",
    "            break\n",
    "        above_idx -= 1\n",
    "\n",
    "    # 이미 존재하는 news_id와 중복을 제외하고 아래에서 가장 가까운 뉴스를 찾기\n",
    "    while below_idx < len(history_news_sorted):\n",
    "        if history_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(history_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(history_news_sorted.loc[below_idx, 'News ID'])\n",
    "            break\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_ids.append(similar_ids)\n",
    "    negative_titles.append(similar_titles)\n",
    "\n",
    "\n",
    "# news_id에서 각 news_id에 대한 유사한 publish 시간 뉴스 기사 찾기\n",
    "negative_train_ids = []\n",
    "negative_train_titles = []\n",
    "used_ids = set(train_ids)  # 중복을 방지하기 위해 used_ids에 train_id를 추가\n",
    "\n",
    "for train_id in train_ids:\n",
    "    idx = train_news_sorted[train_news_sorted['News ID'] == train_id].index[0] \n",
    "    # print(idx)\n",
    "    above_idx, below_idx = idx - 1, idx + 1\n",
    "    similar_ids = []\n",
    "    similar_titles = []\n",
    "\n",
    "    # 이미 존재하는 News ID와 중복된 News를 제외하고 위에서 가장 가까운 두 개의 News를 find\n",
    "    while above_idx >= 0 and len(similar_ids) < 2:\n",
    "        if train_news_sorted.loc[above_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[above_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[above_idx, 'News ID'])\n",
    "        above_idx -= 1\n",
    "\n",
    "    # 이미 존재하는 News ID와 중복된 News를 제외하고 아래에서 가장 가까운 두 개의 News를 find\n",
    "    while below_idx < len(train_news_sorted) and len(similar_ids) < 4:\n",
    "        if train_news_sorted.loc[below_idx, 'News ID'] not in used_ids:\n",
    "            similar_ids.append(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "            similar_titles.append(train_news_sorted.loc[below_idx, 'Title'])\n",
    "            used_ids.add(train_news_sorted.loc[below_idx, 'News ID'])\n",
    "        below_idx += 1\n",
    "\n",
    "    negative_train_ids.append(similar_ids)\n",
    "    negative_train_titles.append(similar_titles)\n",
    "\n",
    "\n",
    "question_ids = [negative_list + [title] for negative_list, title in zip(negative_train_ids, train_ids)]\n",
    "question_titles = [negative_list + [title] for negative_list, title in zip(negative_train_titles, train_titles)]\n",
    "\n",
    "hidden_positions = []\n",
    "\n",
    "# 각 행을 섞고 히든 값의 위치를 저장\n",
    "for row in question_titles:\n",
    "    hidden_value = row[-1]  # 히든 값 (마지막 요소)\n",
    "    random.shuffle(row)  # 전체 행을 섞기\n",
    "    \n",
    "    hidden_index = row.index(hidden_value)  # 히든 값의 새로운 위치 찾기\n",
    "    hidden_positions.append(hidden_index+1)  # 히든 값의 위치 저장\n",
    "\n",
    "\n",
    "number = len(titles)\n",
    "\n",
    "print('[Click History]')\n",
    "for i in range(number):\n",
    "    print(f'{i+1}. click : {titles[i]} / non-click_1: {negative_titles[i][0]}, non-click_2: {negative_titles[i][1]}')\n",
    "    \n",
    "print()\n",
    "print(\"Rank the five candidates for each question based on the user's interest in previously read articles.\")\n",
    "\n",
    "for i, titles in enumerate(question_titles):\n",
    "    print(f\"Question {i+1}) \", end=\"\")\n",
    "    for j, title in enumerate(titles):\n",
    "        # print(f\"{j+1}: {title} / \", end=\"\")\n",
    "        if j == len(titles) - 1:\n",
    "            print(f\"{j+1}: {title}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{j+1}: {title} / \", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nDo not explain reasons in the response, just return a list of numbers for each article.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 : Correct\n",
      "Question 2 : Correct\n",
      "Question 3 : 3\n",
      "Question 4 : 2\n",
      "Question 5 : Correct\n",
      "\n",
      "총 Correct : 3/5개 (60.000%)\n",
      "평균 오차범위 : 0.600\n"
     ]
    }
   ],
   "source": [
    "questions = input(\"질문을 입력하세요: \")\n",
    "\n",
    "# 질문에서 숫자를 추출\n",
    "def extract_numbers(questions):\n",
    "    # pattern = r\"Question \\d+ : ([\\d, ]+)\"\n",
    "    pattern = r\"Question \\d+: ([\\d, ]+)\"\n",
    "    return [list(map(int, num.split(', '))) for num in re.findall(pattern, questions)]\n",
    "\n",
    "numbers_list = extract_numbers(questions)\n",
    "\n",
    "correct_count = 0\n",
    "total_diff = 0\n",
    "\n",
    "diff_count = 0\n",
    "# 각 질문의 숫자 목록에서 hidden_positions 값의 위치 찾기\n",
    "for i, (hidden, numbers) in enumerate(zip(hidden_positions, numbers_list)):\n",
    "    if numbers[0] == hidden:\n",
    "        print(f\"Question {i + 1} : Correct\")\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        position = numbers.index(hidden)\n",
    "        total_diff += abs(position)\n",
    "        print(f\"Question {i + 1} : {position + 1}\")\n",
    "    diff_count += 1\n",
    "\n",
    "# 결과 요약 출력\n",
    "print(f\"\\n총 Correct : {correct_count}/{len(hidden_positions)}개 ({correct_count / len(hidden_positions):.3%})\")\n",
    "if diff_count > 0:\n",
    "    print(f\"평균 오차범위 : {total_diff / diff_count:.3f}\")\n",
    "\n",
    "\n",
    "# #####3\n",
    "# print(\"\\n##########################################\\n\")\n",
    "# # 정답\n",
    "# for i, label in enumerate(hidden_positions):\n",
    "#     print(f\"Question Answer {i+1} : {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Answer 1 : 5\n",
      "Question Answer 2 : 5\n",
      "Question Answer 3 : 4\n",
      "Question Answer 4 : 4\n",
      "Question Answer 5 : 3\n",
      "Question Answer 6 : 5\n",
      "Question Answer 7 : 2\n",
      "Question Answer 8 : 5\n",
      "Question Answer 9 : 1\n",
      "Question Answer 10 : 3\n",
      "Question Answer 11 : 2\n",
      "Question Answer 12 : 1\n",
      "Question Answer 13 : 5\n",
      "Question Answer 14 : 4\n",
      "Question Answer 15 : 5\n",
      "Question Answer 16 : 1\n",
      "Question Answer 17 : 1\n",
      "Question Answer 18 : 1\n"
     ]
    }
   ],
   "source": [
    "# 정답\n",
    "for i, label in enumerate(hidden_positions):\n",
    "    print(f\"Question Answer {i+1} : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1 : Correct\n",
      "Question 2 : 2\n",
      "Question 3 : 4\n",
      "Question 4 : 4\n",
      "Question 5 : 3\n",
      "Question 6 : 5\n",
      "Question 7 : 5\n",
      "Question 8 : 2\n",
      "Question 9 : Correct\n",
      "Question 10 : Correct\n",
      "Question 11 : 3\n",
      "Question 12 : 5\n",
      "Question 13 : 5\n",
      "Question 14 : 3\n",
      "Question 15 : 5\n",
      "Question 16 : 3\n",
      "Question 17 : Correct\n",
      "Question 18 : 2\n",
      "Question 19 : 4\n",
      "Question 20 : 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터를 문자열로 정의\n",
    "input_data = \"\"\"\n",
    "Question 1 : Correct\n",
    "Question 2 : 1\n",
    "Question 3 : 3\n",
    "Question 4 : 3\n",
    "Question 5 : 2\n",
    "Question 6 : 4\n",
    "Question 7 : 4\n",
    "Question 8 : 1\n",
    "Question 9 : Correct\n",
    "Question 10 : Correct\n",
    "Question 11 : 2\n",
    "Question 12 : 4\n",
    "Question 13 : 4\n",
    "Question 14 : 2\n",
    "Question 15 : 4\n",
    "Question 16 : 2\n",
    "Question 17 : Correct\n",
    "Question 18 : 1\n",
    "Question 19 : 3\n",
    "Question 20 : 2\n",
    "\"\"\"\n",
    "\n",
    "# 결과 저장 리스트\n",
    "result = []\n",
    "\n",
    "# 입력 데이터를 줄 단위로 처리\n",
    "for line in input_data.split('\\n'):\n",
    "    # ':'로 줄을 분리\n",
    "    parts = line.split(' : ', 1)  # 1번만 분리해서 예외 방지\n",
    "\n",
    "    # parts의 길이가 2이고 두 번째 부분이 숫자인지 확인\n",
    "    if len(parts) == 2 and parts[1].strip().isdigit():\n",
    "        new_value = int(parts[1].strip()) + 1\n",
    "        result.append(f\"{parts[0]} : {new_value}\")\n",
    "    else:  # 숫자가 없거나 다른 텍스트일 경우 그대로 추가\n",
    "        result.append(line)\n",
    "\n",
    "# 결과 출력\n",
    "output = '\\n'.join(result)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
